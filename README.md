# RAG Question Answering System

## Overview
This project implements a Retrieval-Augmented Generation (RAG) pipeline using LangChain, OpenAI embeddings, and ChromaDB.

## Features
- Web scraping using WebBaseLoader
- Text chunking with RecursiveCharacterTextSplitter
- Semantic search using embeddings
- Vector storage with ChromaDB
- Prompt-based contextual retrieval
- LLM-powered question answering

## Tech Stack
- Python
- LangChain
- OpenAI
- ChromaDB
- Transformers

## Example Use Case
Ask questions about course content and receive context-aware answers generated by an LLM.

## Future Improvements
- Add Streamlit UI
- Deploy using FastAPI
- Add Docker support
